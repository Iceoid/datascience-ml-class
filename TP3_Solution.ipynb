{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP3_Solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iceoid/datascience-ml-class/blob/main/TP3_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUWung2Ki7yv"
      },
      "source": [
        "# Importing Basic Libraries\n",
        "\n",
        "`%pylab inline` imports the basic libraries (numpy, matplotlib)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7Ee64K8i2GZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d70e9c1d-f03d-4d5a-9aa5-b20fb9f8711f"
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpTTF5fxgJNS"
      },
      "source": [
        "---\n",
        "\n",
        "# Scikit-learn\n",
        "\n",
        "Scikit-learn (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.\n",
        "\n",
        "More information can be found on their website https://scikit-learn.org/stable/. This includes tutorials, examples, documentation and overview of algorithms.\n",
        "\n",
        "![sklearn](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEYrq8MALHe4"
      },
      "source": [
        "The library is very comprehensive, almost everything you need for machine learning is available (except complex neural networks).\n",
        "Sklearn also includes many common ML datasets. They are pre-processed and ready to use.\n",
        "\n",
        "We will import the Iris flower dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23LYOpZZi5qY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c054575a-94a8-4c92-cec0-74d6bb8629e0"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "data = iris.data\n",
        "target = iris.target\n",
        "\n",
        "# Select only versicolor and virginica flowers\n",
        "data_x = data[50:]\n",
        "data_y = target[50:]\n",
        "\n",
        "# Binarize the labels (to 0 or 1)\n",
        "labelencoder = preprocessing.LabelEncoder()\n",
        "labelencoder.fit(data_y)\n",
        "data_y = labelencoder.transform(data_y)\n",
        "\n",
        "# Shuffle the dataset\n",
        "data_x, data_y = shuffle(data_x, data_y, random_state=42)\n",
        "\n",
        "print(\"Inputs shape:\", data_x.shape) # Print shape of dataset\n",
        "print(\"Outputs shape:\", data_y.shape) # Print shape of dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs shape: (100, 4)\n",
            "Outputs shape: (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3YD-OACEgJ1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "e8556011-7a01-4fa7-e88c-ed756dbedfa4"
      },
      "source": [
        "print(\"First 10 entries of the dataset:\")\n",
        "print(data_x[0:10])\n",
        "print(data_y[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 10 entries of the dataset:\n",
            "[[6.3 2.8 5.1 1.5]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [5.  2.  3.5 1. ]\n",
            " [7.  3.2 4.7 1.4]]\n",
            "[1 1 1 0 0 0 0 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75QEsXQcPX1K"
      },
      "source": [
        "---\n",
        "\n",
        "## k-NN and KDE Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jrFwJ-tOovk"
      },
      "source": [
        "# Distance function, returns the distance between x and y\n",
        "def distance(x, y):\n",
        "    return np.sum((x - y) ** 2, axis=-1)\n",
        "\n",
        "# Takes in one unknown input, training dataset, training labels and k\n",
        "# Outputs the predicted class\n",
        "def knn(x, dataset_x, dataset_y, k):\n",
        "    argmin_indices = argsort(distance(x, dataset_x))\n",
        "    k_nearest_neighbours = dataset_y[argmin_indices[0:k]]\n",
        "\n",
        "    class_0 = np.sum(k_nearest_neighbours == 0)\n",
        "    class_1 = np.sum(k_nearest_neighbours == 1)\n",
        "\n",
        "    if class_0 > class_1:\n",
        "        return 0\n",
        "    elif class_1 > class_0:\n",
        "        return 1\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "# Takes in unknown inputs, training dataset, training labels and k (optional, default = 3)\n",
        "# Outputs the array of predictions\n",
        "def knn_batch(unknowns_x, dataset_x, dataset_y, k=3):\n",
        "    return np.array([knn(x, dataset_x, dataset_y, k) for x in unknowns_x])\n",
        "\n",
        "# Gaussian kernel function with sigma s\n",
        "def kernel(x, s):\n",
        "    return np.exp(-(x**2)/(s**2)) # Generalized \"gaussian-like\" kernel equation: e^-|x|^p / s^p\n",
        "\n",
        "# Takes in one unknown input, training dataset, training labels and sigma\n",
        "# Outputs the predicted class\n",
        "def kde(x, dataset_x, dataset_y, s):\n",
        "    weights = kernel(distance(x, dataset_x), s)\n",
        "    class_0 = np.sum(weights[dataset_y == 0])\n",
        "    class_1 = np.sum(weights[dataset_y == 1])\n",
        "\n",
        "    return 0 if class_0 > class_1 else 1\n",
        "\n",
        "# Takes in unknown inputs, training dataset, training labels and sigma (optional, default = 4)\n",
        "# Outputs the array of predictions\n",
        "def kde_batch(unknowns_x, dataset_x, dataset_y, s=4):\n",
        "    return np.array([kde(x, dataset_x, dataset_y, s) for x in unknowns_x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PKayhsIiqfq"
      },
      "source": [
        "---\n",
        "\n",
        "## Model Validation\n",
        "\n",
        "Scikit-learn has implementations for dataset splitting, but first try to implement them in numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83R_jZ0LP-DP"
      },
      "source": [
        "# Accuracy of prediction for binary classification labels\n",
        "def accuracy(predicted_y, real_y):\n",
        "    return 1 - np.mean(np.clip(np.abs(predicted_y - real_y), 0, 1))\n",
        "\n",
        "# Shuffles and splits the dataset (dataset_x, dataset_y) into (train_x, train_y, test_x, test_y). test_split (a number between 0 and 1) is the amount of data to be kept for testing.\n",
        "def split_dataset(dataset_x, dataset_y, test_split):\n",
        "    dataset_x, dataset_y = shuffle(dataset_x, dataset_y) #Shuffle the dataset\n",
        "    idx = int(len(dataset_x) * (1 - test_split))\n",
        "    return dataset_x[:idx], dataset_y[:idx], dataset_x[idx:], dataset_y[idx:]\n",
        "\n",
        "# Tests the knn algorithm, returns the accuracy on test_x\n",
        "def test_knn(train_x, train_y, test_x, test_y, k):\n",
        "    pred_y = knn_batch(test_x, train_x, train_y, k)\n",
        "    return accuracy(pred_y, test_y)\n",
        "\n",
        "# Tests the kde algorithm, returns the accuracy on test_x\n",
        "def test_kde(train_x, train_y, test_x, test_y, s):\n",
        "    pred_y = kde_batch(test_x, train_x, train_y, s)\n",
        "    return accuracy(pred_y, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTPt382HVx-5"
      },
      "source": [
        "### Model Validation - Exercises\n",
        "1.   Split the dataset into 70% train and 30% test.\n",
        "2.   Using $k=3$ and $\\sigma=0.1$ for k-NN and KDE respectively, what is the accuracy obtained on the test set?\n",
        "  * 94% for k-NN and 95% for KDE.\n",
        "3.   Is it valid to manually modify $k$ and $\\sigma$ until the accuracy increases? Discuss.\n",
        "  * No, it is not valid to modify hyperparameters using the test set. For correct expected risk estimation, we must use a validation split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gw1tXd2To6N"
      },
      "source": [
        "train_x, train_y, test_x, test_y = split_dataset(data_x, data_y, 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlwuU6bKUIKm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a33ab9c2-be48-4572-e647-ea7857aedb73"
      },
      "source": [
        "print(\"KNN Accuracy:\", test_knn(test_x, test_y, train_x, train_y, 3))\n",
        "print(\"KDE Accuracy:\", test_kde(test_x, test_y, train_x, train_y, 0.1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN Accuracy: 0.9428571428571428\n",
            "KDE Accuracy: 0.9571428571428572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIAAm7SGYE8B"
      },
      "source": [
        "### Hyperparameter Selection - Exercises\n",
        "\n",
        "As seen in class, we must split the dataset into three (train, validate, test) in order to select hyperparameters.\n",
        "\n",
        "4.   Using `split_dataset` implemented in **1)**, split the dataset into 60% train, 20% validate, 20% test. (Hint: First split the dataset into 60/40, then split the latter portion in two again.)\n",
        "5.   Find the best $k$ and $\\sigma$ using the validation set. Use linear search for k-NN (eg. $k=(13, 11, 9, ...)$) and a decay regime for $\\sigma$ (eg. start with $\\sigma_0=10$ and multiply by $0.9$ for each iteration $(\\sigma_{i+1}=0.9\\sigma_i)$, stop when $\\sigma<{0.001}$).\n",
        "6.   Merge the validation set into the training set. After training a new model with the best hyperparameters on this larger training set, verify and confim good generalization by testing on the test set. What is the final accuracy on the best hyperparameters?\n",
        "  * 95% for k-NN with $k=7$ and 95% for KDE with $\\sigma=0.47$.\n",
        "7.   Shuffle the dataset randomly and try **4), 5)** and **6)** again a few times. What do you notice? Are the best hyperparameters different each time? Discuss.\n",
        "  * There are large variations across different runs. This might suggest that the testing dataset is too small and we are not getting a good estimate of the expected risk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsHoxLVAVfSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "b98772b8-81fb-4037-9a61-6a81cac170e5"
      },
      "source": [
        "def big_test(iters=10):\n",
        "    for i in range(iters):\n",
        "\n",
        "        # Split the dataset randomly\n",
        "        train_x, train_y, test_x, test_y = split_dataset(data_x, data_y, 0.4)\n",
        "        valid_x, valid_y, test_x, test_y = split_dataset(test_x, test_y, 0.5)\n",
        "\n",
        "        # Find the best k\n",
        "        best_k_score = 0\n",
        "        best_k = 13\n",
        "\n",
        "        for k in range(13, 0, -2):\n",
        "            score = test_knn(train_x, train_y, valid_x, valid_y, k)\n",
        "            if score >= best_k_score:\n",
        "                best_k_score = score\n",
        "                best_k = k\n",
        "\n",
        "        # Find the best s\n",
        "        best_s_score = 0\n",
        "        best_s = 10\n",
        "        s = 10\n",
        "\n",
        "        while (s >= 0.001):\n",
        "            score = test_kde(train_x, train_y, valid_x, valid_y, s)\n",
        "            if score >= best_s_score:\n",
        "                best_s_score = score\n",
        "                best_s = s\n",
        "            s = s * 0.9\n",
        "\n",
        "        # Print results\n",
        "        print(\"KNN:\", f\"k={best_k},\", f\"validation={best_k_score}\")\n",
        "        print(\"KDE:\", f\"s={best_s},\", f\"validation={best_s_score}\")\n",
        "\n",
        "        train_valid_x = np.concatenate([train_x, valid_x])\n",
        "        train_valid_y = np.concatenate([train_y, valid_y])\n",
        "\n",
        "        print(\"KNN:\", f\"test={test_knn(train_valid_x, train_valid_y, test_x, test_y, best_k)}\")\n",
        "        print(\"KDE:\", f\"test={test_kde(train_valid_x, train_valid_y, test_x, test_y, best_s)}\")\n",
        "        print(\"____\")\n",
        "big_test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN: k=7, validation=1.0\n",
            "KDE: s=0.47101286972462447, validation=1.0\n",
            "KNN: test=0.95\n",
            "KDE: test=0.95\n",
            "____\n",
            "KNN: k=1, validation=0.95\n",
            "KDE: s=0.009550049507968268, validation=1.0\n",
            "KNN: test=1.0\n",
            "KDE: test=1.0\n",
            "____\n",
            "KNN: k=5, validation=1.0\n",
            "KDE: s=0.27812838944369356, validation=1.0\n",
            "KNN: test=0.95\n",
            "KDE: test=0.95\n",
            "____\n",
            "KNN: k=9, validation=1.0\n",
            "KDE: s=0.38152042447694584, validation=0.95\n",
            "KNN: test=1.0\n",
            "KDE: test=1.0\n",
            "____\n",
            "KNN: k=1, validation=0.95\n",
            "KDE: s=0.5233476330273605, validation=1.0\n",
            "KNN: test=0.85\n",
            "KDE: test=0.85\n",
            "____\n",
            "KNN: k=5, validation=1.0\n",
            "KDE: s=0.27812838944369356, validation=1.0\n",
            "KNN: test=0.95\n",
            "KDE: test=0.9\n",
            "____\n",
            "KNN: k=7, validation=0.95\n",
            "KDE: s=0.0026972160559060807, validation=0.9\n",
            "KNN: test=1.0\n",
            "KDE: test=0.65\n",
            "____\n",
            "KNN: k=1, validation=1.0\n",
            "KDE: s=0.013100205086376222, validation=1.0\n",
            "KNN: test=0.9\n",
            "KDE: test=0.9\n",
            "____\n",
            "KNN: k=1, validation=0.95\n",
            "KDE: s=0.005075287860564165, validation=0.95\n",
            "KNN: test=0.85\n",
            "KDE: test=0.85\n",
            "____\n",
            "KNN: k=1, validation=1.0\n",
            "KDE: s=0.005639208733960182, validation=1.0\n",
            "KNN: test=1.0\n",
            "KDE: test=1.0\n",
            "____\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObnLDHPTXY2o"
      },
      "source": [
        "### Cross-Validation with Scikit-learn\n",
        "\n",
        "The dataset might be too small to accurately perform hyperparameter selection using splitting alone. We can try cross-validation.\n",
        "\n",
        "Since this is harder to implement, we will directly use the scikit-learn library.\n",
        "\n",
        "8.   Using `split_dataset` implemented in **1)**, split the dataset into 80% train and 20% test.\n",
        "9.   Using the `KFold` method in scikit-learn (cross-validation), implement cross-validation on k-NN and KDE using the training set only.\n",
        "10.  Using **9)** and a n_splits value of 10, select the best hyperparameters for k-NN and KDE using the training set only with the same linear search as **5)**.\n",
        "11.  Using the best hyperparameters found, train a new model using the entire training set (80%), verify and confim good generalization by testing on the test set (20%). What is the final average accuracy on the best hyperparameters?\n",
        "  * 100% for k-NN with $k=5$ and 100% for KDE with $\\sigma=0.28$.\n",
        "12.   Shuffle the dataset randomly and try **8), 10)** and **11)** again a few times. What do you notice? Are the values more stable compared to simple splitting? Discuss.\n",
        "  * The variations across runs is smaller, and the average accuracy is higher. Cross-validation helps in cases where the dataset is small."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWdAytcycbzP"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Tests the knn algorithm using cross-validation\n",
        "def test_knn_cv(train_x, train_y, k, n_splits):\n",
        "    sum_accuracy = 0\n",
        "    for train, valid in kf.split(train_x):\n",
        "        t_x, t_y, v_x, v_y = train_x[train], train_y[train], train_x[valid], train_y[valid]\n",
        "        p_y = knn_batch(v_x, t_x, t_y, k)\n",
        "        sum_accuracy += accuracy(p_y, v_y)\n",
        "    return sum_accuracy / n_splits\n",
        "\n",
        "# Tests the kde algorithm using cross-validation\n",
        "def test_kde_cv(train_x, train_y, s, n_splits):\n",
        "    sum_accuracy = 0\n",
        "    for train, valid in kf.split(train_x):\n",
        "        t_x, t_y, v_x, v_y = train_x[train], train_y[train], train_x[valid], train_y[valid]\n",
        "        p_y = kde_batch(v_x, t_x, t_y, s)\n",
        "        sum_accuracy += accuracy(p_y, v_y)\n",
        "    return sum_accuracy / n_splits\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HI5FQ5emXmm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "1cba4909-422e-49f9-9e72-b55cecfe1998"
      },
      "source": [
        "folds = 10\n",
        "def big_test(iters=10):\n",
        "    for i in range(iters):\n",
        "\n",
        "        # Split the dataset randomly\n",
        "        train_x, train_y, test_x, test_y = split_dataset(data_x, data_y, 0.2)\n",
        "\n",
        "        # Find the best k\n",
        "        best_k_score = 0\n",
        "        best_k = 13\n",
        "\n",
        "        for k in range(13, 0, -2):\n",
        "            score = test_knn_cv(train_x, train_y, k, folds)\n",
        "            if score >= best_k_score:\n",
        "                best_k_score = score\n",
        "                best_k = k\n",
        "\n",
        "        # Find the best s\n",
        "        best_s_score = 0\n",
        "        best_s = 10\n",
        "        s = 10\n",
        "\n",
        "        while (s >= 0.001):\n",
        "            score = test_kde_cv(train_x, train_y, s, folds)\n",
        "            if score >= best_s_score:\n",
        "                best_s_score = score\n",
        "                best_s = s\n",
        "            s = s * 0.9\n",
        "\n",
        "        # Print results\n",
        "        print(\"KNN:\", f\"k={best_k},\", f\"validation={best_k_score}\")\n",
        "        print(\"KDE:\", f\"s={best_s},\", f\"validation={best_s_score}\")\n",
        "\n",
        "\n",
        "        print(\"KNN:\", f\"test={test_knn(train_x, train_y, test_x, test_y, best_k)}\")\n",
        "        print(\"KDE:\", f\"test={test_kde(train_x, train_y, test_x, test_y, best_s)}\")\n",
        "        print(\"____\")\n",
        "big_test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN: k=5, validation=0.95\n",
            "KDE: s=0.27812838944369356, validation=0.9375\n",
            "KNN: test=1.0\n",
            "KDE: test=1.0\n",
            "____\n",
            "KNN: k=9, validation=0.9625\n",
            "KDE: s=0.009550049507968268, validation=0.95\n",
            "KNN: test=0.95\n",
            "KDE: test=0.95\n",
            "____\n",
            "KNN: k=7, validation=0.9625\n",
            "KDE: s=0.27812838944369356, validation=0.9625\n",
            "KNN: test=0.95\n",
            "KDE: test=0.9\n",
            "____\n",
            "KNN: k=5, validation=0.95\n",
            "KDE: s=0.010611166119964741, validation=0.95\n",
            "KNN: test=1.0\n",
            "KDE: test=0.95\n",
            "____\n",
            "KNN: k=5, validation=0.9625\n",
            "KDE: s=0.006961986091308867, validation=0.95\n",
            "KNN: test=0.9\n",
            "KDE: test=0.9\n",
            "____\n",
            "KNN: k=7, validation=0.9625\n",
            "KDE: s=0.2503155504993242, validation=0.9375\n",
            "KNN: test=1.0\n",
            "KDE: test=1.0\n",
            "____\n",
            "KNN: k=13, validation=0.9625\n",
            "KDE: s=0.009550049507968268, validation=0.95\n",
            "KNN: test=0.95\n",
            "KDE: test=0.95\n",
            "____\n",
            "KNN: k=7, validation=0.975\n",
            "KDE: s=0.5814973700304006, validation=0.9875\n",
            "KNN: test=0.95\n",
            "KDE: test=0.85\n",
            "____\n",
            "KNN: k=7, validation=0.975\n",
            "KDE: s=0.009550049507968268, validation=0.9625\n",
            "KNN: test=0.9\n",
            "KDE: test=0.9\n",
            "____\n",
            "KNN: k=1, validation=0.9375\n",
            "KDE: s=0.009550049507968268, validation=0.9375\n",
            "KNN: test=0.95\n",
            "KDE: test=1.0\n",
            "____\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUOS295lo8Eg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}